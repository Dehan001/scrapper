website to scrape: https://research.com/scientists-rankings/computer-science

crome drive: 

selenium: https://selenium-python.readthedocs.io/


from selenium import webdriver
from selenium.webdriver.common.by import By
import time

# URL of the webpage
url = "https://science.nasa.gov/exoplanets/exoplanet-catalog/"
# url = "https://disfold.com/sector/energy/companies/?page=1"

# Initialize the Chrome driver
driver = webdriver.Chrome()

# Give the driver some time to load the page
time.sleep(5)

# Open the webpage
driver.get(url)

# Locate elements with the specified class name
items = driver.find_elements(By.CLASS_NAME, "hds-content-item")

print(len(items))

# Close the driver after use
driver.quit()
    # planet_info_blocks = WebDriverWait(driver, 10).until(
    # EC.presence_of_all_elements_located((By.CLASS_NAME, "smd-acf-grid-col")))
    # print(planet_info_blocks[0].text)
    # # Find all planet info blocks